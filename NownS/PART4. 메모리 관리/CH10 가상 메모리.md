# CH10. 가상 메모리

- 가상 메모리란 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법

# 배경

- 기본적으로 메모리 관련 알고리즘은 코드가 물리 메모리 상에 존재한다는 요구 조건을 만족
- 동적 적재로 조금 완화할 수 있지만, 특별한 주의와 작업이 필요할 수 있음
- 실행 중인 코드가 물리 메모리에 있어야 한다는 건 타당해 보이지만, 여러 이상한 점이 있음
    - 프로그램에는 잘 발생하지 않는 오류 사항을 처리하기도 함. 이런 코드는 거의 실행되지 않음
    - 배열, 리스트, 테이블 등이 필요 이상으로 많은 공간을 점유할 수도 있음
    - 프로그램 내 특정 옵션은 잘 사용되지 않기도 하고, 프로그램이 전부 사용된다고 하더라도 모든 부분이 동시에 필요하지는 않음
- 일부분만 메모리에 올릴 수 있다면 여러 이점이 있음
    - 프로그램이 물리 메모리 크기의 제약을 받지 않음
    - 각 프로그램이 더 작은 메모리를 차지, 더 많은 프로그램을 동시에 수행 가능, 이용률과 처리율 증가
    - 프로그램을 메모리에 올리고 스왑하는데 필요한 I/O 횟수가 줄어들어 프로그램이 빠르게 실행됨
- 가상 메모리 - 물리 메모리와 논리 메모리 개념을 분리
    - 작은 메모리로 얼마든지 큰 가상 주소를 제공 가능
    - 프로그래머는 메모리 문제 없이 프로그램의 로직에만 집중할 수 있음
- 가상 주소 공간 - 프로세스가 메모리에 저장되는 논리적인 뷰
    - 논리 메모리는 0부터 연속적인 공간으로 이루어짐
    - 물리 메모리는 페이지 프레임으로 이루어짐, 할당된 프레임들은 연속적이지 않을 수 있음
    - 이를 매핑하는 것은 메모리 관리 장치(MMU)의 역할
- 가상 메모리를 통해 페이지를 공유하여 파일이나 메모리가 여러 프로세스에 의해 공유될 수 있다.

# 요구 페이징(Demand Paging)

## 개념

- 필요할 때만 페이지를 메모리에 적재하는 방법
- 이 둘을 구별하기 위한 하드웨어 지원 필요
    - 유효 비트 - 해당 페이지가 메모리에 있음
    - 무효 비트 - 해당 페이지가 메모리에 올라와 있지 않음
- 메모리에 올라와 있지 않은 페이지에 접근하려고 하면 `페이지 폴트 트랩` 발생
- 페이지 폴트 처리 과정
    - 프로세스 내부 테이블(PCB와 함께 유지됨)을 검사하여 메모리 참조의 유/무효를 확인
    - 무효한 페이지라면 프로세스 종료, 유효한 참조라면 보조기억장치에서 가져와야 함
    - 가용 프레임 하나 확인
    - 보조저장장치에 새로 할당된 프레임으로 해당 페이지를 읽도록 요청
    - 페이지가 메모리에 있음을 알리기 위해 페이지 테이블과 프로세스 내부 테이블 갱신
    - 트랩에 의해 중단된 명령어 재실행
- 순수 요구 페이징
    - 어떤 페이지가 필요하기 전까지는 페이지를 메모리에 절대 적재하지 않는 방법
    - 이 방법을 사용하면 처음 프로세스를 시작할때 페이지 폴트가 지속적으로 발생 후 모두 올라오면 더이상 폴트가 발생하지 않음
- 참조의 지역성이라는 성질 때문에 요구 페이징이 만족할 만한 성능을 보여 줌
- 필요한 하드웨어
    - 페이지 테이블 - 유/무효 비트를 사용 가능해야 함
    - 보조저장장치 - 메인 메모리에 없는 모든 페이지 저장, 고성능의 디스크(스왑 장치) → 스왑 공간
- 페이지 폴트 이후 프로세스 재실행이 가능해야 함

## 가용 프레임 리스트

- 페이지 폴트를 해결하기 위해 가용 프레임 풀인 `가용 프레임 리스트`를 유지해야 함
- zero-fill-on-demand라는 기법 사용
    - 할당되기 전에 0으로 모두 채워져서 이전 내용을 지움

## 요구 페이징의 성능

- 실질 접근 시간은 페이지 폴트율에 비례함
    - 페이지 폴트율을 낮게 유지하는 것이 중요
- 스왑 공간(특별한 공간으로 관리)의 관리 필요

# 쓰기 시 복사

- fork 시스템 콜을 이용하여 첫 요구 페이징조차 생략
- 부모의 페이지를 다 복사해오는 대신 쓰기 시 복사를 사용
    - 자식 프로세스가 시작할 때 부모의 페이지를 당분간 함께 사용
    - 둘중 한 프로세스가 공유중인 페이지에 쓸 때 복사본을 생성
    - 수정을 하는 페이지에 대해서만 복사본이 생김 → 코드와 같은 곳은 자식과 부모 간 그대로 공유
- vfork의 경우, 부모 프로세스가 보류되고 자식의 부모의 공간 사용, 쓰기 시 복사 사용 x
    - 부모 주소 공간의 페이지를 수정하면 변경된 페이지가 부모 프로세스에 그대로 보임
    - 자식이 주소 공간의 페이지들에 변경을 가하지 않도록 주의해야 함

# 페이지 교체

- 다중 프로그래밍 정도를 올리면 메모리 과할당 발생 가능
    - 가용 프레임이 없는 상황
    - 운영체제의 몇 가지 선택
        - 프로세스 종료 → 좋은 선택은 아님
        - 스와핑을 통해 스왑 아웃, 페이지 스와핑과 페이지 교체의 결합

## 기본적인 페이지 교체

- 빈 프레임이 없다면 사용되지 않는 프레임을 제거
- 요구 페이징에서 중요한 부분이 프레임 할당 알고리즘, 페이지 교체 알고리즘
- 페이지 교체에서 I/O가 많은 비용이 들기 때문에, 적절한 알고리즘 설계가 중요

## FIFO 페이지 교체

- 메모리에 올라온지 가장 오래된 페이지를 교체
- 이해하기 쉽고, 코딩하기도 쉽지만 효율적이지는 않음
- 프레임의 개수가 많다고 항상 폴트가 덜 이러나는 것은 아님(Belady의 모순)

## 최적 페이지 교체(Optimal)

- 가장 낮은 페이지 폴트율을 보이는 알고리즘
- 실제 구현이 사실상 불가능, 미래를 예측해야 하기 때문

## LRU 페이지 교체

- Least Recently Used 알고리즘
- 가장 오랜 기간동안 사용되지 않은 페이지 교체

## LRU 근사 페이지 교체

- LRU는 하드웨어적인 지원이 필요
- 참조 비트 형태의 간단한 지원을 통해 LRU 근사 알고리즘 구현

### 부가적 참조 비트 알고리즘

- 일정 간격마다 참조 비트를 기록함으로써 추가적 선후 관계 정보를 얻음

### 2차 기회 알고리즘

- 사용하는 비트 수를 극단적으로 줄여 참조 비트만 남김
- FIFO를 기반으로 참조 비트가 0이면 교체하고, 1이면 다시한번 기회를 줌

### 개선된 2차 기회 알고리즘

- 참조 비트와 변경 비트를 이용하여 추가 개선
- 네가지 등급을 이용하여 페이지 교체

## 계수 기반 페이지 교체

- LFU 알고리즘 - 참조 횟수가 가장 적은 페이지를 교체하는 방법
- MFU 알고리즘 - 가장 작은 참조 횟수를 가진 페이지가 가장 최근 참조된 것이고, 앞으로 사용될 것이라는 판단

## 페이지 버퍼링 알고리즘

- 페이지 교체 알고리즘과 병행하여 사용되는 버퍼링 기법
- 가용 프레임 풀을 이용한 알고리즘, 페이지 I/O 속도를 더 최적화 가능

## 애플리케이션과 페이지 교체

- 몇몇 경우 가상 메모리를 사용하는 것보다 직접 접근하는 편이 더 나은 경우도 있음(ex: 데이터베이스)
- 몇몇 운영 체제는 보조저장장치 파티션을 단순한 논리적 블록 배열로 사용할 수 있게 해주기도 함
    - raw disk라고 불리며, raw I/O라고 불림

# 프레임의 할당

## 최소 할당 프레임 수

- 다양한 제한이 존재
    - 가용 프레임 수보다 더 많이 할당 불가
    - 최소한 몇 페이지는 할당해야 함
- 최소한의 프레임을 할당해야 하는 이유 → 성능
- 컴퓨터 아키텍쳐에 의해 정의됨

## 할당 알고리즘

- 균등 할당 : 모든 프로세스가 n등분하여 프레임을 받아가는 방법
- 비례 할당 : 가용 메모리를 각 프로세스의 크기 비율에 맞추어 할당하는 방법

## 전역 대 지역 할당

- 전역 교체
    - 프로세스가 교체할 프레임을 모든 프레임을 대상으로 찾는 경우
- 지역 교체
    - 프로세스가 자기에게 할당된 프레임 중에서만 교체될 프레임을 찾는 경우
- 임계값 기준 가용 메모리 유지

## 비균등 메모리 접근

- NUMA 시스템에서는 각자 자신의 로컬 메모리를 소유
- 더 많은 CPU를 수용할 수 있으므로 더 높은 처리량과 병렬 처리 달성 가능

# 스래싱

- 과도한 페이징 작업을 의미
- 실제 실행보다 더 많은 시간을 페이징에 사용하고 있는 상황

## 원인

- CPU 이용률이 낮아지면 다중 프로그래밍 정도를 높인다
- 페이지 폴트가 지속적으로 이루어지면서 페이징 장치에 대한 큐잉 진행, 준비 큐가 비게 됨
- CPU 이용률이 더욱 감소, 이로 인해 다중 프로그래밍 증가, 무한 반복
- 특정 지점 이후에는 다중 프로그래밍 정도를 낮춰야 함
- 최소한의 프레임 개수를 보장해야 함 - 실제 사용하는 프레임의 수를 확인, 지역성 모델
    - 특정 지역에서만 메모리를 집중 참조함을 의미

## 작업 집합 모델

- 지역성을 토대로 함
- 작업 집합을 기반으로 프로그램 지역성을 계산

## 페이지 폴트 빈도

- 페이지 폴트율의 상한과 하한을 정해 두고, 페이지 폴트율이 상한을 넘으면 프레임을 더 할당하고, 페이지 폴트율이 하한보다 낮아지면 그 프로세스의 프레임 수를 줄인다

## 현재 관행

- 충분한 메모리를 제공하는 것이 가장 사용자를 위한 것임
- 물리 메모리를 충분히 장착하는 것이 가장 좋음

# 메모리 압축

- 페이징의 대안으로, 압축을 사용할 수 있음
- 여러 프레임을 하나의 프레임으로 압축함으로써 메모리 사용량 감소
- 압축 알고리즘의 속도와 얻을 수 있는 감소량 사이 트레이드오프 존재
- 최근 압축의 병렬 사용을 통해 압축 알고리즘의 향상을 가져옴

# 커널 메모리 할당

- 커널 메모리의 경우 별도의 메모리 풀에서 할당받아야 함
    - 다양한 크기의 자료구조가 있기 대문에 단편화에 의한 낭비 최소화
    - 물리 메모리 상에서 연속적인 메모리가 있어야 하는 경우가 있음

## 버디 시스템

- 물리적으로 연속된 페이지로 이루어진 고정된 크기의 세그먼트로 메모리 할당
- 2의 거듭제곱 할당기에 의해 해당 단위로 할당
- 인접한 버디들이 손쉽게 큰 세그먼트로 합쳐질 수 있음
- 2의 거듭제곱으로 올림하기 때문에 단편화를 가져올 수 있음

## 슬랩 할당 → ??

- 연속된 페이지로 구성된 슬랩에 캐시를 통해 커널 객체 저장
- 단편화로 인해 낭비되는 메모리가 없음 - 각 캐시는 객체의 크기로 나누어진 덩어리로 구성
- 메모리 요청이 빠르게 처리될 수 있음 - 객체는 미리 생성되어 있고, 캐시에서 쉽게 할당 가능

# 기타 고려 사항

## 프리페이징

- 순수 요구 페이징에서 프로세스가 시작될 때 많은 페이지 폴트 발생
- 프리페이징을 통해 필요한 페이지의 일부 또는 전부를 한번에 메모리에 가져올 수 있음
- 프리페이징 사용과 페이지 폴트의 비용을 비교해 볼 필요가 있음

## 페이지 크기

- 페이지 크기 감소는 페이지의 수를 증가시키고, 페이지 테이블 크기 증가
- 메모리 사용 효율을 위해서는 작은 페이지가 좋음
- I/O 시간의 경우 지연 시간과 탐색 시간을 줄이도록 하는 큰 페이지 크기가 좋음
- 작은 페이지 크기를 갖는 경우 지역성을 더욱 정밀하게 추적할 수 있도록 해 줌
- 페이지 폴트 횟수를 줄이기 위해서는 큰 페이지 크기가 좋음
- 최적의 해결책은 존재하지 않음. 현재는 큰 페이지를 선호하는 추세로, 4096바이트가 보편적인 페이지 크기

## TLB Reach

- TLB로부터 액세스할 수 있는 메모리 공간의 크기
- 한 프로세스의 작업 집합이 TLB에 모두 들어올 수 있으면 가장 좋음
- 페이지 테이블까지 메모리 참조가 넘어간다면 수행 시간이 매우 느려지게 됨
- TLB 사이즈를 키우거나, 페이지 크기를 늘리면 TLB Reach를 늘릴 수 있음

## 역 페이지 테이블

- 각 물리 메모리 프레임마다 한 항목을 가짐
- 각 페이지 프레임에 어떤 가상 메모리 페이지가 저장되어 있는지 정보만 유지함으로써 필요한 물리 메모리 양을 줄임

## 프로그램 구조

- 사용자나 컴파일러가 요구 페이징의 특성을 이해함으로써 성능을 크게 개선할 수 있음
- 자료 구조와 프로그래밍 구조를 잘 선택함으로써 지역성을 향상할 수 있고, 페이지 폴트율을 줄일 수 있음
    - 스택은 한쪽 끝만 참조하기 때문에 지역성 상승
    - 해시는 참조를 분산시키므로 지역성이 나쁨
- 루틴을 페이지 경계에 걸치지 않도록 할당하여 루틴을 한 페이지 내에 완전히 들어가도록 하거나, 서로 호출하는 빈도가 높은 루틴은 서로 같은 페이지에 위치시킬 수 있음

## I/O 상호 잠금과 페이지 잠금

- 일부 페이지는 메모리에 붙박이로 고정하는 것이 필요한 경우가 있음
    - I/O 가 사용자 공간에서 이루어질 때, 전역 교체를 통해 대기중인 페이지로 인식되어 아웃되면 안된다
- 두가지 해결법이 있음
    - 사용자 공간에는 I/O를 하지 않는 방식 → 시스템 공간에서만 I/O를 하고 이동 → 속도 느림
    - 페이지를 메모리에서 잠금하는 방법
- 잠금 비트를 이용하여 여러 상황에서 유용하게 사용가능
- 잠금 비트를 언젠가는 해제해야 하는데, 버그로 인해 해제가 되지 않으면 사용할 수 없게 됨, 따라서 조심해서 사용할 필요가 있음